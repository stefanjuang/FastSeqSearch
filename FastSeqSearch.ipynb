{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48XIEhqXL77f"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "The approach leverages the strengths of both FAISS and fastdtw to efficiently handle the search and refinement process:\n",
        "\n",
        "FAISS: Efficiently retrieves a large initial candidate pool based on the last step of the query sequence. This is fast and handles high-dimensional data well.\n",
        "fastdtw: Iteratively refines the candidate pool by considering increasingly longer subsequences, making it feasible to handle long sequences without getting bogged down by the complexity of full DTW computations for all candidates.\n",
        "This combination ensures that we maintain efficiency while still getting accurate results.\n",
        "\n",
        "Summary of the Approach\n",
        "Initial Candidate Retrieval: Use FAISS to quickly retrieve an initial set of candidates based on the last step of the query sequence.\n",
        "Iterative Refinement: Use fastdtw to iteratively refine the candidate pool. Start with the last step of the query sequence and progressively consider longer subsequences.\n",
        "At each step, compute the DTW distance for the current subsequence with the candidates.\n",
        "Sort the candidates based on the DTW distance and remove the bottom 10%.\n",
        "Continue until the candidate set is sufficiently small.\n",
        "Final Selection: Once the candidate pool is sufficiently small, compute the full DTW distance for the remaining candidates and select the one with the smallest distance.\n",
        "'''\n",
        "\n",
        "\n",
        "# fast way\n",
        "import numpy as np\n",
        "from fastdtw import fastdtw\n",
        "from scipy.spatial.distance import euclidean\n",
        "import faiss\n",
        "import os\n",
        "\n",
        "def create_index(vectors):\n",
        "    \"\"\"\n",
        "    Creates a FAISS index from a given set of vectors.\n",
        "    Args:\n",
        "    vectors (numpy.ndarray): A numpy array of shape (nb, d) where 'nb' is the number of base vectors and 'd' is the dimension.\n",
        "    Returns:\n",
        "    faiss.IndexFlatL2: The created FAISS index.\n",
        "    \"\"\"\n",
        "    d = vectors.shape[1]  # dimension of the vectors\n",
        "    index = faiss.IndexFlatL2(d)  # L2 distance index\n",
        "    index.add(vectors)\n",
        "    return index\n",
        "\n",
        "def faiss_search(index, query, k=1000):\n",
        "    \"\"\"\n",
        "    Search for k nearest neighbors in the FAISS index.\n",
        "    Args:\n",
        "    index (faiss.IndexFlatL2): The FAISS index.\n",
        "    query (numpy.ndarray): The query vector.\n",
        "    k (int): Number of nearest neighbors to return.\n",
        "    Returns:\n",
        "    np.ndarray: Indices of the nearest neighbors.\n",
        "    np.ndarray: Distances to the nearest neighbors.\n",
        "    \"\"\"\n",
        "    D, I = index.search(query, k)\n",
        "    return I, D\n",
        "\n",
        "def fastdtw_distance(seq1, seq2):\n",
        "    \"\"\"\n",
        "    Computes the DTW distance between two sequences using the fastdtw algorithm.\n",
        "    Args:\n",
        "    seq1 (numpy.ndarray): The first sequence.\n",
        "    seq2 (numpy.ndarray): The second sequence.\n",
        "    Returns:\n",
        "    float: The DTW distance between the sequences.\n",
        "    \"\"\"\n",
        "    distance, _ = fastdtw(seq1, seq2, dist=euclidean)\n",
        "    return distance\n",
        "\n",
        "context_length = 10\n",
        "sample = 100000\n",
        "\n",
        "# Generate Sample Data\n",
        "sequences = [np.random.rand(context_length, 256 * 4 * 4) for _ in range(sample)]\n",
        "flattened_sequences = np.array(sequences).reshape(context_length * sample, -1)  # Flatten the sequences for FAISS indexing\n",
        "\n",
        "# Create FAISS Index\n",
        "index = create_index(flattened_sequences)\n",
        "\n",
        "# Define a Query Sequence and Iteratively Refine the Candidate List\n",
        "query_sequence = np.random.rand(context_length, 256 * 4 * 4)  # Example query sequence\n",
        "\n",
        "# Step 1: Use the last step of the query sequence to find initial candidates\n",
        "last_step_query = query_sequence[-1].reshape(1, -1)\n",
        "initial_candidates, _ = faiss_search(index, last_step_query, k=1000)  # Start with 1000 candidates\n",
        "\n",
        "# Convert initial candidates to a set for efficient refinement\n",
        "candidate_set = set(initial_candidates.flatten())\n",
        "\n",
        "# Step 2: Iteratively refine the candidate list\n",
        "for i in range(2, len(query_sequence) + 1):\n",
        "    subseq_query = query_sequence[-i:].reshape(-1, 256 * 4 * 4)\n",
        "    distances = []\n",
        "    for candidate_idx in candidate_set:\n",
        "        candidate_seq = sequences[candidate_idx].reshape(context_length, 256 * 4 * 4)\n",
        "        distance = fastdtw_distance(subseq_query, candidate_seq[-i:])\n",
        "        distances.append((candidate_idx, distance))\n",
        "\n",
        "    # Sort distances and remove the bottom 10%\n",
        "    distances.sort(key=lambda x: x[1])\n",
        "    cutoff_index = max(1, len(distances) - len(distances) // 10)\n",
        "    candidate_set = set([idx for idx, dist in distances[:cutoff_index]])\n",
        "\n",
        "    if len(candidate_set) == 1:\n",
        "        break\n",
        "\n",
        "# Step 3: Find the most similar sequence in the refined candidate list\n",
        "highest_match = None\n",
        "highest_score = float('inf')\n",
        "\n",
        "for candidate_idx in candidate_set:\n",
        "    candidate_seq = sequences[candidate_idx].reshape(context_length, 256 * 4 * 4)\n",
        "    distance = fastdtw_distance(query_sequence, candidate_seq)\n",
        "    if distance < highest_score:\n",
        "        highest_score = distance\n",
        "        highest_match = candidate_idx\n",
        "\n",
        "print(f\"The most similar sequence is at index {highest_match} with a DTW distance of {highest_score}.\")\n"
      ]
    }
  ]
}